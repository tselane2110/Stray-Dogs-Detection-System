{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tselane2110/stray-dogs-detection-system/blob/main/Model%20Training/data_preprocessing_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-Processing for Stanford Dog Dataset"
      ],
      "metadata": {
        "id": "AxVahrPm8ooV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui2hdJw0W_V0"
      },
      "source": [
        "## 1. Uploading the fypdataset.zip and annotations.zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlPO-yu5ka9I"
      },
      "outputs": [],
      "source": [
        "!unzip /content/fypdataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZa2mnpLXEc4"
      },
      "source": [
        "## 2. Functions to convert annotation files from xml to txt (yolov5 version)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import pickle\n",
        "import xml.etree.ElementTree as ET\n",
        "from os import listdir, getcwd\n",
        "from os.path import join\n",
        "\n",
        "dirs = ['fypdataset']\n",
        "classes = [\n",
        "           \"Chihuahua\", \"toy_terrier\", \"Rhodesian_ridgeback\", \"basset\", \"beagle\", \"bloodhound\", \"bluetick\", \"black-and-tan_coonhound\", \"Walker_hound\", \"English_foxhound\", \"redbone\", \"Italian_greyhound\", \"whippet\", \"Ibizan_hound\", \"Saluki\", \"Weimaraner\", \"Staffordshire_bullterrier\", \"American_Staffordshire_terrier\", \"golden_retriever\", \"Labrador_retriever\", \"Chesapeake_Bay_retriever\", \"German_short-haired_pointer\", \"Brittany_spaniel\", \"kuvasz\", \"schipperke\", \"malinois\", \"kelpie\", \"Rottweiler\", \"miniature_pinscher\", \"EntleBucher\", \"boxer\", \"Great_Dane\", \"Saint_Bernard\", \"Eskimo_dog\", \"basenji\", \"Leonberg\", \"Pembroke\", \"Cardigan\", \"Mexican_hairless\", \"dingo\", \"African_hunting_dog\"       ]\n",
        "\n",
        "def getImagesInDir(dir_path):\n",
        "    image_list = []\n",
        "    for filename in os.listdir(dir_path+\"/images\"):\n",
        "      image_list.append(filename)\n",
        "\n",
        "    return image_list\n",
        "\n",
        "def convert(size, box):\n",
        "    dw = 1./(size[0])\n",
        "    dh = 1./(size[1])\n",
        "    x = (box[0] + box[1])/2.0 - 1\n",
        "    y = (box[2] + box[3])/2.0 - 1\n",
        "    w = box[1] - box[0]\n",
        "    h = box[3] - box[2]\n",
        "    x = x*dw\n",
        "    w = w*dw\n",
        "    y = y*dh\n",
        "    h = h*dh\n",
        "    return (x,y,w,h)\n",
        "\n",
        "def convert_annotation(dir_path, output_path, image_path):\n",
        "    basename = os.path.basename(image_path)\n",
        "    basename_no_ext = os.path.splitext(basename)[0]\n",
        "    # image_path is like n02085620_10074.jpg\n",
        "    # basename_no_ext is like n02085620_10074\n",
        "    # dir_path is /content/fypdataset/\n",
        "    # output_path is /content/fypdataset/yolo\n",
        "    # in_file should be: /content/fypdataset/labels/n02085620_10074\n",
        "    in_file = open(dir_path + '/labels/' + basename_no_ext)\n",
        "    out_file = open(output_path + \"/\" + basename_no_ext + '.txt', 'w')\n",
        "    tree = ET.parse(in_file)\n",
        "    root = tree.getroot()\n",
        "    size = root.find('size')\n",
        "    w = int(size.find('width').text)\n",
        "    h = int(size.find('height').text)\n",
        "\n",
        "    for obj in root.iter('object'):\n",
        "        difficult = obj.find('difficult').text\n",
        "        cls = obj.find('name').text\n",
        "        if cls not in classes or int(difficult)==1:\n",
        "            continue\n",
        "        cls_id = 0\n",
        "        xmlbox = obj.find('bndbox')\n",
        "        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text),\n",
        "             float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n",
        "        bb = convert((w,h), b)\n",
        "        out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
        "\n",
        "cwd = getcwd()\n",
        "\n",
        "for dir_path in dirs:\n",
        "    full_dir_path = cwd + '/' + dir_path\n",
        "    print(full_dir_path)\n",
        "    output_path = full_dir_path +'/yolo'\n",
        "    print(output_path)\n",
        "\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "        print(\"output path created!\")\n",
        "\n",
        "    image_paths = getImagesInDir(full_dir_path)\n",
        "    list_file = open(full_dir_path + '.txt', 'w')\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        list_file.write(image_path + '\\n')\n",
        "        convert_annotation(full_dir_path, output_path, image_path)\n",
        "    list_file.close()\n",
        "\n",
        "    print(\"Finished processing: \" + dir_path)"
      ],
      "metadata": {
        "id": "HqPeehgbtdoo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c2750d2-4523-4dc1-b4f0-908351128439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fypdataset\n",
            "/content/fypdataset/yolo\n",
            "Finished processing: fypdataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train, Val, Test split:"
      ],
      "metadata": {
        "id": "-SCw9xA_67k1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiTue97jV6o8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3de8ded-264c-4f19-b427-96ca10833074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no of images:  6876\n",
            "no of labels:  6876\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "# split the image data into train, val, and test sets\n",
        "\n",
        "path_to_annotation_files = []\n",
        "path_to_image_files = []\n",
        "annotation_root= \"/content/fypdataset/yolo\"\n",
        "root_path = \"/content/fypdataset\"\n",
        "for class_id in os.listdir(annotation_root):\n",
        "  annotation_path = os.path.join(annotation_root, class_id)       #/content/fypdataset/yolo/n02085620_1298.txt\n",
        "  text=class_id                         # we need i == n02110806_3971.jpg\n",
        "  d=re.search ('\\d+_\\d+', text)\n",
        "  if d.group(0)!=None:\n",
        "    b=d.group(0)\n",
        "    x=\"n\"+b+\".jpg\"     #x= n02085620_1298.jpg\n",
        "  image_path = os.path.join(root_path, \"images/\"+x)   #/content/fypdataset/images/n02085620_1298.jpg\n",
        "  path_to_annotation_files.append(annotation_path)\n",
        "  path_to_image_files.append(image_path)\n",
        "\n",
        "\n",
        "\n",
        "print(\"no of images: \", len(path_to_annotation_files))\n",
        "print(\"no of labels: \", len(path_to_image_files))\n",
        "\n",
        "train_images, val_images, train_annotations, val_annotations= train_test_split(path_to_image_files, path_to_annotation_files,\n",
        "                                                                               test_size=0.2, random_state=1)\n",
        "\n",
        "val_images, test_images, val_annotations, test_annotations=train_test_split(val_images, val_annotations,\n",
        "                                                                           test_size=0.5, random_state=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images) #/content/fypdataset/images/n02085620_10074.jpg\n",
        "print(train_annotations) #/content/fypdataset/yolo/n02085620_1073.txt"
      ],
      "metadata": {
        "id": "8Jqq1bUJTSic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B11Ga5JRoxkv"
      },
      "source": [
        "## 4. moving the train, test and val split files into their respective folders:\n",
        "\n",
        "* I created 2 new folders as images1 and labels1 in fypdataset folder, and then I created training, testing and validation folders within each of them. So that I can delete the old images and yolo folder (I also deleted the initial labels/annotations folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNu7NsT5HxFP"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "def moves_files_to_folder(list_of_files, destination_folder):\n",
        "  for f in list_of_files:\n",
        "    try:\n",
        "      shutil.copy(f, destination_folder)\n",
        "    except:\n",
        "      print(f)\n",
        "      assert False\n",
        "\n",
        "moves_files_to_folder(train_images, \"/content/fypdataset/images1/training\")\n",
        "moves_files_to_folder(val_images, \"/content/fypdataset/images1/validation\")\n",
        "moves_files_to_folder(test_images, \"/content/fypdataset/images1/testing\")\n",
        "moves_files_to_folder(train_annotations, \"/content/fypdataset/labels1/training\")\n",
        "moves_files_to_folder(val_annotations, \"/content/fypdataset/labels1/validation\")\n",
        "moves_files_to_folder(test_annotations, \"/content/fypdataset/labels1/testing\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Now deleting the old images and yolo folder:"
      ],
      "metadata": {
        "id": "Q3VNnSwfeV1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree(\"/content/fypdataset/images\")\n",
        "shutil.rmtree(\"/content/fypdataset/yolo\")"
      ],
      "metadata": {
        "id": "S5hnBhRbeaPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. converting fypdataset into zipped file,, and downloading it, so that we dont lose our data.\n"
      ],
      "metadata": {
        "id": "Q5cmxxve5vwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!zip /content/content/fypdataset.zip -r /content/content/fypdataset\n",
        "# from google.colab import files\n",
        "# files.download(\"/content/fypdataset.zip\")\n",
        "\n",
        "# you can also just double-click on the zip file as shown in the files tab"
      ],
      "metadata": {
        "id": "2VcbyZqqwekj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1FScWB8wATq5bdN6x9H_BZOVxE9KipENo",
      "authorship_tag": "ABX9TyNF2mYVOFKF3l89VcNGRlBF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}